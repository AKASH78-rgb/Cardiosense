# -*- coding: utf-8 -*-
"""hey123.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-WUYsA2OGzgm8loYs5QeZCdpwPBHWu-k
"""

import kagglehub, pathlib

dataset_id = "drkhaledmohsin/national-heart-foundation-2023-ecg-dataset"
dataset_path = kagglehub.dataset_download(dataset_id)
print("Downloaded to:", dataset_path)

# Point to the folder that actually contains class subfolders
data_dir = pathlib.Path(dataset_path) / "ECG Data"
assert data_dir.exists(), f"Could not find 'ECG Data' in {dataset_path}"
print("Using data_dir:", data_dir)

# Quick sanity check of classes
classes = sorted([p.name for p in data_dir.iterdir() if p.is_dir()])
print("Classes:", classes)
assert len(classes) >= 2, "Need at least two class folders inside 'ECG Data'."

import tensorflow as tf

from tensorflow.keras.utils import image_dataset_from_directory

IMG_SIZE = (224, 224)    # Safe, standard size
BATCH = 32
VAL_SPLIT = 0.2

train_ds = image_dataset_from_directory(
    data_dir,
    validation_split=VAL_SPLIT,
    subset="training",
    seed=123,
    image_size=IMG_SIZE,
    batch_size=BATCH
)
val_ds = image_dataset_from_directory(
    data_dir,
    validation_split=VAL_SPLIT,
    subset="validation",
    seed=123,
    image_size=IMG_SIZE,
    batch_size=BATCH
)

# Some images may be single-channel; make sure everything is 3-channel
def to_rgb(x, y):
    if tf.shape(x)[-1] == 1:
        x = tf.image.grayscale_to_rgb(x)
    return x, y

from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Input(shape=(*IMG_SIZE, 3)),
    layers.Rescaling(1./255),

    layers.Conv2D(32, 3, activation="relu"),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation="relu"),
    layers.MaxPooling2D(),
    layers.Conv2D(128, 3, activation="relu"),
    layers.MaxPooling2D(),

    layers.Conv2D(128, 3, activation="relu"),
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.4),
    layers.Dense(128, activation="relu"),
    layers.Dropout(0.3),
    layers.Dense(len(classes), activation="softmax")
])

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

ckpt_path = "/content/ecg_cnn_best.keras"
callbacks = [
    EarlyStopping(monitor="val_accuracy", patience=5, restore_best_weights=True),
    ModelCheckpoint(ckpt_path, monitor="val_accuracy", save_best_only=True)
]

EPOCHS = 20
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=callbacks,
    verbose=1
)

print("Best model saved to:", ckpt_path)

import matplotlib.pyplot as plt

plt.figure()
plt.plot(history.history["accuracy"], label="train acc")
plt.plot(history.history["val_accuracy"], label="val acc")
plt.xlabel("Epoch"); plt.ylabel("Accuracy"); plt.legend(); plt.title("Training vs Validation Accuracy")
plt.show()

plt.figure()
plt.plot(history.history["loss"], label="train loss")
plt.plot(history.history["val_loss"], label="val loss")
plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.legend(); plt.title("Training vs Validation Loss")
plt.show()

import numpy as np
NUM_CLASSES = len(classes)

y_true = []
y_pred = []
for bx, by in val_ds:
    preds = model.predict(bx, verbose=0)
    y_true.extend(by.numpy().tolist())
    y_pred.extend(np.argmax(preds, axis=1).tolist())

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

print(classification_report(y_true, y_pred, target_names=train_ds.class_names))
cm = confusion_matrix(y_true, y_pred)

# Plot CM
import matplotlib.pyplot as plt
fig, ax = plt.subplots()
im = ax.imshow(cm)
ax.set_xticks(range(NUM_CLASSES)); ax.set_yticks(range(NUM_CLASSES))
ax.set_xticklabels(train_ds.class_names, rotation=45, ha="right")
ax.set_yticklabels(train_ds.class_names)
ax.set_xlabel("Predicted"); ax.set_ylabel("True"); ax.set_title("Confusion Matrix")
for i in range(NUM_CLASSES):
    for j in range(NUM_CLASSES):
        ax.text(j, i, cm[i, j], ha="center", va="center")
plt.colorbar(im); plt.tight_layout(); plt.show()

import tensorflow as tf
import numpy as np
import requests
from io import BytesIO
from PIL import Image

# Load model
model = tf.keras.models.load_model(ckpt_path)

# Download image from URL
url ="https://www.bing.com/images/search?view=detailV2&ccid=LkvHNiBF&id=FA3EA0889D634212E70ABDB9C5B5DD7E54BBCB7A&thid=OIP.LkvHNiBFkb9rs59rlJ-VbQHaH0&mediaurl=https%3a%2f%2fthumbs.dreamstime.com%2fz%2fnormal-abnormal-ecg-cardiogram-diagram-schematic-raster-illustration-medical-science-educational-illustration-normal-283508494.jpg&exph=1690&expw=1600&q=ecg+images+abnormal+&simid=608009199559512827&FORM=IRPRST&ck=5352F94C205AEB7EE5D4DC74DF25CAAB&selectedIndex=7&itb=0"
response = requests.get(url)
img = Image.open(BytesIO(response.content))

# Preprocess image
IMG_SIZE = (224, 224)   # change to your model input size
img = img.resize(IMG_SIZE)
x = tf.keras.utils.img_to_array(img)

if x.shape[-1] == 1:  # grayscale
    x = tf.image.grayscale_to_rgb(x)

x = np.expand_dims(x, 0) / 255.0   # normalize

# Predict
probs=model.predict(x)
pred_idx=int(np.argmax(probs))
print("Predicted:",train_ds.class_names[pred_idx],"confidence:",float(probs[0][pred_idx]) )

import tensorflow as tf
import numpy as np
import requests
from io import BytesIO
from PIL import Image

# Load model
ckpt_path = "/content/ecg_cnn_best.keras"  # change to your actual path
model = tf.keras.models.load_model(ckpt_path)

# Define class names (must match training order!)
class_names = ["Abnormal Heartbeat Patients", "Myocardial Infarction Patients","Normal Person","Patient that have History of Myocardial Infraction"]  # <-- replace with your own classes

# Download image from URL
url = "https://th.bing.com/th/id/OIP.viaw3kkFzJNgKAHOv5b0qHaE8?w=145&h=180&c=7&r=0&o=5&dpr=1.3&pid=1.7"
response = requests.get(url)
img = Image.open(BytesIO(response.content)).convert("RGB")

# Preprocess image
IMG_SIZE = (224, 224)   # change to your model input size
img = img.resize(IMG_SIZE)
x = tf.keras.utils.img_to_array(img)
x = np.expand_dims(x, 0) / 255.0   # normalize to [0,1]

# Predict
probs = model.predict(x, verbose=0)
pred_idx = int(np.argmax(probs))

print("Predicted:", class_names[pred_idx],
      "| Confidence:", float(probs[0][pred_idx]))